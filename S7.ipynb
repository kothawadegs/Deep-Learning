{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "S7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36987a3bdf964164ae6a1978071e8d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3cf82f72c467485b94e1b21edb2b8aab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c464e13f40974f4d8b997dd1fb6c9b40",
              "IPY_MODEL_1390090997a84c93a392c5d09f9b3b0a"
            ]
          }
        },
        "3cf82f72c467485b94e1b21edb2b8aab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c464e13f40974f4d8b997dd1fb6c9b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_727776b11c4b4f63bf5c2bca337cc586",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f21792a5c8a45a78ef0f6cbb1e3ae9f"
          }
        },
        "1390090997a84c93a392c5d09f9b3b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8600a35271c4dd4a14080ac3a5446fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:03, 43743004.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_952f173742ee40ce91506160b0bea27c"
          }
        },
        "727776b11c4b4f63bf5c2bca337cc586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f21792a5c8a45a78ef0f6cbb1e3ae9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8600a35271c4dd4a14080ac3a5446fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "952f173742ee40ce91506160b0bea27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kothawadegs/Deep-Learning/blob/master/S7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbdg0z4poCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPogbueepoCh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Training a Classifier\n",
        "=====================\n",
        "\n",
        "This is it. You have seen how to define neural networks, compute loss and make\n",
        "updates to the weights of the network.\n",
        "\n",
        "Now you might be thinking,\n",
        "\n",
        "What about data?\n",
        "----------------\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "-  For images, packages such as Pillow, OpenCV are useful\n",
        "-  For audio, packages such as scipy and librosa\n",
        "-  For text, either raw Python or Cython based loading, or NLTK and\n",
        "   SpaCy are useful\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "It has the classes: â€˜airplaneâ€™, â€˜automobileâ€™, â€˜birdâ€™, â€˜catâ€™, â€˜deerâ€™,\n",
        "â€˜dogâ€™, â€˜frogâ€™, â€˜horseâ€™, â€˜shipâ€™, â€˜truckâ€™. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        ".. figure:: /_static/img/cifar10.png\n",
        "   :alt: cifar10\n",
        "\n",
        "   cifar10\n",
        "\n",
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "1. Loading and normalizing CIFAR10\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "Using ``torchvision``, itâ€™s extremely easy to load CIFAR10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yVpodAMpoCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kjt4e2TpoCk",
        "colab_type": "text"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Tjigo2poCl",
        "colab_type": "code",
        "outputId": "9f3b98ee-6522-4a1b-8540-b314eb993c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "36987a3bdf964164ae6a1978071e8d24",
            "3cf82f72c467485b94e1b21edb2b8aab",
            "c464e13f40974f4d8b997dd1fb6c9b40",
            "1390090997a84c93a392c5d09f9b3b0a",
            "727776b11c4b4f63bf5c2bca337cc586",
            "1f21792a5c8a45a78ef0f6cbb1e3ae9f",
            "a8600a35271c4dd4a14080ac3a5446fb",
            "952f173742ee40ce91506160b0bea27c"
          ]
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [ transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "     transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "     transforms.ToTensor(),  \n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36987a3bdf964164ae6a1978071e8d24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cj433rtpoCn",
        "colab_type": "text"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daA7bADhpoCo",
        "colab_type": "code",
        "outputId": "32d083f2-f0a2-45fe-c3db-2cc2643656af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  dog   car plane  frog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28OpHA_LpoCq",
        "colab_type": "text"
      },
      "source": [
        "2. Define a Convolution Neural Network\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Copy the neural network from the Neural Networks section before and modify it to\n",
        "take 3-channel images (instead of 1-channel images as it was defined).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jjLwLLQpoCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "dropout_value = 0.1\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels= 32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32 # RF =3\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False,dilation = 2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32 # rf=7\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 16 #rf=9 \n",
        "\n",
        "        # CONVOLUTION BLOCK 2 \n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels= 128 , kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 16 # rf=13\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128 , kernel_size=(3, 3), padding=1, bias=False, groups = 128),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 16 #rf = 15\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 8\n",
        "\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels= 256 , kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 8\n",
        "       \n",
        "\n",
        "        \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)\n",
        "        ) # output_size = 1\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels= 256 , out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(10),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        ) \n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "  \n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock5(x)\n",
        "\n",
        "        x = self.gap(x)        \n",
        "        x = self.convblock7(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "net = Net()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    net = net.cuda()\n",
        "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
        "#     #cudnn.benchmark = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuwTVQ7W1tVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "dafd6030-0001-44f0-d9c1-a7fb94002aac"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3,32,32))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "              ReLU-2           [-1, 32, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 32, 32, 32]              64\n",
            "           Dropout-4           [-1, 32, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 30, 30]          18,432\n",
            "              ReLU-6           [-1, 64, 30, 30]               0\n",
            "       BatchNorm2d-7           [-1, 64, 30, 30]             128\n",
            "           Dropout-8           [-1, 64, 30, 30]               0\n",
            "         MaxPool2d-9           [-1, 64, 15, 15]               0\n",
            "           Conv2d-10          [-1, 128, 15, 15]          73,728\n",
            "             ReLU-11          [-1, 128, 15, 15]               0\n",
            "      BatchNorm2d-12          [-1, 128, 15, 15]             256\n",
            "          Dropout-13          [-1, 128, 15, 15]               0\n",
            "           Conv2d-14          [-1, 128, 15, 15]           1,152\n",
            "             ReLU-15          [-1, 128, 15, 15]               0\n",
            "      BatchNorm2d-16          [-1, 128, 15, 15]             256\n",
            "          Dropout-17          [-1, 128, 15, 15]               0\n",
            "        MaxPool2d-18            [-1, 128, 7, 7]               0\n",
            "           Conv2d-19            [-1, 256, 7, 7]         294,912\n",
            "             ReLU-20            [-1, 256, 7, 7]               0\n",
            "      BatchNorm2d-21            [-1, 256, 7, 7]             512\n",
            "          Dropout-22            [-1, 256, 7, 7]               0\n",
            "        AvgPool2d-23            [-1, 256, 1, 1]               0\n",
            "           Conv2d-24             [-1, 10, 1, 1]           2,560\n",
            "================================================================\n",
            "Total params: 392,864\n",
            "Trainable params: 392,864\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.06\n",
            "Params size (MB): 1.50\n",
            "Estimated Total Size (MB): 6.57\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3zSTvpk17qC",
        "colab_type": "text"
      },
      "source": [
        "Define a Loss function and optimizer ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Let's use a Classification Cross-Entropy loss and SGD with momentum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ9KikFl19Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjXm7pwd2Euv",
        "colab_type": "text"
      },
      "source": [
        "1.Train the network ^^^^^^^^^^^^^^^^^^^^\n",
        "This is when things start to get interesting. We simply have to loop over our data iterator, and feed the inputs to the network and optimize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jr9jyay2BzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf66a49b-7171-42df-9f48-2791ab9ac39d"
      },
      "source": [
        "for epoch in range(25):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.890\n",
            "[1,  4000] loss: 1.643\n",
            "[1,  6000] loss: 1.517\n",
            "[1,  8000] loss: 1.421\n",
            "[1, 10000] loss: 1.357\n",
            "[1, 12000] loss: 1.287\n",
            "[2,  2000] loss: 1.210\n",
            "[2,  4000] loss: 1.174\n",
            "[2,  6000] loss: 1.112\n",
            "[2,  8000] loss: 1.105\n",
            "[2, 10000] loss: 1.095\n",
            "[2, 12000] loss: 1.060\n",
            "[3,  2000] loss: 0.982\n",
            "[3,  4000] loss: 1.002\n",
            "[3,  6000] loss: 0.977\n",
            "[3,  8000] loss: 0.938\n",
            "[3, 10000] loss: 0.944\n",
            "[3, 12000] loss: 0.947\n",
            "[4,  2000] loss: 0.889\n",
            "[4,  4000] loss: 0.895\n",
            "[4,  6000] loss: 0.877\n",
            "[4,  8000] loss: 0.850\n",
            "[4, 10000] loss: 0.844\n",
            "[4, 12000] loss: 0.832\n",
            "[5,  2000] loss: 0.807\n",
            "[5,  4000] loss: 0.793\n",
            "[5,  6000] loss: 0.822\n",
            "[5,  8000] loss: 0.807\n",
            "[5, 10000] loss: 0.805\n",
            "[5, 12000] loss: 0.778\n",
            "[6,  2000] loss: 0.753\n",
            "[6,  4000] loss: 0.756\n",
            "[6,  6000] loss: 0.750\n",
            "[6,  8000] loss: 0.743\n",
            "[6, 10000] loss: 0.756\n",
            "[6, 12000] loss: 0.736\n",
            "[7,  2000] loss: 0.719\n",
            "[7,  4000] loss: 0.722\n",
            "[7,  6000] loss: 0.716\n",
            "[7,  8000] loss: 0.724\n",
            "[7, 10000] loss: 0.713\n",
            "[7, 12000] loss: 0.705\n",
            "[8,  2000] loss: 0.687\n",
            "[8,  4000] loss: 0.707\n",
            "[8,  6000] loss: 0.670\n",
            "[8,  8000] loss: 0.657\n",
            "[8, 10000] loss: 0.691\n",
            "[8, 12000] loss: 0.684\n",
            "[9,  2000] loss: 0.661\n",
            "[9,  4000] loss: 0.671\n",
            "[9,  6000] loss: 0.674\n",
            "[9,  8000] loss: 0.626\n",
            "[9, 10000] loss: 0.654\n",
            "[9, 12000] loss: 0.638\n",
            "[10,  2000] loss: 0.645\n",
            "[10,  4000] loss: 0.630\n",
            "[10,  6000] loss: 0.623\n",
            "[10,  8000] loss: 0.623\n",
            "[10, 10000] loss: 0.633\n",
            "[10, 12000] loss: 0.631\n",
            "[11,  2000] loss: 0.646\n",
            "[11,  4000] loss: 0.603\n",
            "[11,  6000] loss: 0.607\n",
            "[11,  8000] loss: 0.613\n",
            "[11, 10000] loss: 0.601\n",
            "[11, 12000] loss: 0.619\n",
            "[12,  2000] loss: 0.610\n",
            "[12,  4000] loss: 0.577\n",
            "[12,  6000] loss: 0.587\n",
            "[12,  8000] loss: 0.604\n",
            "[12, 10000] loss: 0.605\n",
            "[12, 12000] loss: 0.588\n",
            "[13,  2000] loss: 0.582\n",
            "[13,  4000] loss: 0.583\n",
            "[13,  6000] loss: 0.564\n",
            "[13,  8000] loss: 0.579\n",
            "[13, 10000] loss: 0.589\n",
            "[13, 12000] loss: 0.574\n",
            "[14,  2000] loss: 0.545\n",
            "[14,  4000] loss: 0.560\n",
            "[14,  6000] loss: 0.571\n",
            "[14,  8000] loss: 0.549\n",
            "[14, 10000] loss: 0.572\n",
            "[14, 12000] loss: 0.565\n",
            "[15,  2000] loss: 0.523\n",
            "[15,  4000] loss: 0.549\n",
            "[15,  6000] loss: 0.552\n",
            "[15,  8000] loss: 0.542\n",
            "[15, 10000] loss: 0.553\n",
            "[15, 12000] loss: 0.578\n",
            "[16,  2000] loss: 0.514\n",
            "[16,  4000] loss: 0.539\n",
            "[16,  6000] loss: 0.534\n",
            "[16,  8000] loss: 0.551\n",
            "[16, 10000] loss: 0.546\n",
            "[16, 12000] loss: 0.524\n",
            "[17,  2000] loss: 0.548\n",
            "[17,  4000] loss: 0.519\n",
            "[17,  6000] loss: 0.538\n",
            "[17,  8000] loss: 0.523\n",
            "[17, 10000] loss: 0.504\n",
            "[17, 12000] loss: 0.537\n",
            "[18,  2000] loss: 0.511\n",
            "[18,  4000] loss: 0.525\n",
            "[18,  6000] loss: 0.525\n",
            "[18,  8000] loss: 0.520\n",
            "[18, 10000] loss: 0.520\n",
            "[18, 12000] loss: 0.506\n",
            "[19,  2000] loss: 0.516\n",
            "[19,  4000] loss: 0.515\n",
            "[19,  6000] loss: 0.512\n",
            "[19,  8000] loss: 0.503\n",
            "[19, 10000] loss: 0.489\n",
            "[19, 12000] loss: 0.493\n",
            "[20,  2000] loss: 0.495\n",
            "[20,  4000] loss: 0.514\n",
            "[20,  6000] loss: 0.501\n",
            "[20,  8000] loss: 0.488\n",
            "[20, 10000] loss: 0.496\n",
            "[20, 12000] loss: 0.494\n",
            "[21,  2000] loss: 0.484\n",
            "[21,  4000] loss: 0.495\n",
            "[21,  6000] loss: 0.488\n",
            "[21,  8000] loss: 0.503\n",
            "[21, 10000] loss: 0.501\n",
            "[21, 12000] loss: 0.474\n",
            "[22,  2000] loss: 0.488\n",
            "[22,  4000] loss: 0.481\n",
            "[22,  6000] loss: 0.481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCs7KWYV2MbQ",
        "colab_type": "text"
      },
      "source": [
        "1.Test the network on the test data ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "We have trained the network for 2 passes over the training dataset. But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mRqG2Q26rRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrbWxaos6uVq",
        "colab_type": "text"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPMkj-yr6vVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = net(images)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0etEoIdO6xba",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The outputs are energies for the 10 classes. Higher the energy for a class, the more the network thinks that the image is of the particular class. So, let's get the index of the highest energy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue47akqa2OcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON_WmGB665sl",
        "colab_type": "text"
      },
      "source": [
        "The results seem pretty good.\n",
        "\n",
        "Let us look at how the network performs on the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8eWUcgI66qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)  # missing line from original code\n",
        "        labels = labels.to(device)  # missing line from original code\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJrp5Add69D1",
        "colab_type": "text"
      },
      "source": [
        "That looks waaay better than chance, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did not perform well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_qgnt_Y6_bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)  # missing line from original code\n",
        "        labels = labels.to(device)  # missing line from original code\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}